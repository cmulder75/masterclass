{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype NLP tasks | Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "## Prototype NLP Tasks\n",
    "## Created by:  Coenraad F. Mulder\n",
    "## Date:        03-12-2021\n",
    "## Purpose:     Prototype NLP tasks to: \n",
    "##              - create a clean corpus\n",
    "##              - extract key topics from cleaned corpus\n",
    "##              - perform sentiment analysis on the cleaned corpus\n",
    "#######################################################################\n",
    "# Libraries\n",
    "#######################################################################\n",
    "import pandas as pd                         # DataFrame functionality\n",
    "from datetime import datetime, timedelta    # Date and time manipulation\n",
    "import nltk                                 # NLP toolkit\n",
    "import gensim                               # Dictionary and Corpus\n",
    "import gensim.corpora as corpora            # Corpus\n",
    "import ast                                  # String to list conversion\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import contractions                         # Replace contractions in text\n",
    "import re                                   # Convert regular expressions\n",
    "from pprint import pprint                   # Pretty print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Tweet Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet Length</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282552117501952</td>\n",
       "      <td>WHO says no deaths reported from Omicron yet a...</td>\n",
       "      <td>HappinessPatrol</td>\n",
       "      <td>145</td>\n",
       "      <td>['say', 'death', 'reported', 'yet', 'covid', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282552075529984</td>\n",
       "      <td>Will the Omicron Travel Restrictions Work? - T...</td>\n",
       "      <td>ZZsheyn</td>\n",
       "      <td>83</td>\n",
       "      <td>['travel', 'restriction', 'work', 'new', 'york...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282547906339072</td>\n",
       "      <td>@VaccineJo Omicron is simply a fitness test, a...</td>\n",
       "      <td>stevenjfrisch</td>\n",
       "      <td>148</td>\n",
       "      <td>['vaccinejo', 'simply', 'fitness', 'test', 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282539433926912</td>\n",
       "      <td>@johnpavlovitz SWEET JESUS JOHN! WHY OH WHY! J...</td>\n",
       "      <td>butterflybees11</td>\n",
       "      <td>176</td>\n",
       "      <td>['johnpavlovitz', 'sweet', 'jesus', 'john', 'o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282530949033984</td>\n",
       "      <td>@Channel4News @krishgm I'm done humouring Fasc...</td>\n",
       "      <td>Anne_Other1</td>\n",
       "      <td>206</td>\n",
       "      <td>['channel4news', 'krishgm', 'done', 'humouring...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date             Tweet Id  \\\n",
       "0 2021-12-04  1467282552117501952   \n",
       "1 2021-12-04  1467282552075529984   \n",
       "2 2021-12-04  1467282547906339072   \n",
       "3 2021-12-04  1467282539433926912   \n",
       "4 2021-12-04  1467282530949033984   \n",
       "\n",
       "                                          Tweet Text         Username  \\\n",
       "0  WHO says no deaths reported from Omicron yet a...  HappinessPatrol   \n",
       "1  Will the Omicron Travel Restrictions Work? - T...          ZZsheyn   \n",
       "2  @VaccineJo Omicron is simply a fitness test, a...    stevenjfrisch   \n",
       "3  @johnpavlovitz SWEET JESUS JOHN! WHY OH WHY! J...  butterflybees11   \n",
       "4  @Channel4News @krishgm I'm done humouring Fasc...      Anne_Other1   \n",
       "\n",
       "   Tweet Length                                              words  \n",
       "0           145  ['say', 'death', 'reported', 'yet', 'covid', '...  \n",
       "1            83  ['travel', 'restriction', 'work', 'new', 'york...  \n",
       "2           148  ['vaccinejo', 'simply', 'fitness', 'test', 'pr...  \n",
       "3           176  ['johnpavlovitz', 'sweet', 'jesus', 'john', 'o...  \n",
       "4           206  ['channel4news', 'krishgm', 'done', 'humouring...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################################\n",
    "# Import Tweets from web scrape - expecting 'tweets.xlsx' in current dir\n",
    "########################################################################\n",
    "tweets_df = pd.read_excel(\"tweets.xlsx\")\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Task 1 - Topic modeling using Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "Topic modeling is the method of uncovering hidden structures in sets of texts or documents. When dealing with unlabelled data, the supervised LDA method is not effective for topic modeling, the unsupervised LDA (Un-LDA) method guarantees convergence during the iterative topic modeling process (Wang et al., 2021). The unsupervised LDA produces a probalistic representation of a document or set of documents as a mixture of topics, however, as one of the shortcomings of LDA is its inability to model sequentiallity of data, the LDA can effectively be extended with segmentation algorithms such as stochastic word alignment and integer linear programming to be more segmentally coherent (Camelin et al., 2011). The authors, Thielmann et al., have demonstrated how the combination of One-Class Support Vector Machines (SVM) and LDA can be used to effectively classify documents, presenting with greater than 80% of target data correctly classified (Thielmann et al., 2020). As the Tweeted data is unlabelled, the unsupervised LDA can be used to effectively classify the Tweets according to probalistic topics.\n",
    "\n",
    "As can be expected from the random Tweets, each Tweet may cover more than one topic, and each topic may consist of one or more words. This is where LDA is especially effective by highlighting hidden topics within the Tweets, thus assisting to unlock the meaning of these Tweets. LDA assigns each Tweet to a mixture of topics, which allows for a more realistic clustering of the Tweets (as opposed to hard clustering by algorithms such as K-means clustering or decision trees).\n",
    "\n",
    "LDA requires that all text be converted to a simple vector representation, and the only hyperparameter that requires tweaking is the number of topics in the LDA algorithm. For this prototype, the number of topics was set as 5 (as the keyword search already reduced the topic list to everything to do with Omicron). The preprocessing was done by the web crawler, providing a tokenized 'words' list for each Tweet. As these 'words' lists were imported from Excel, they were imported as strings (not actual lists). This is where the 'ast' Python package was handy to convert the strings to its actual list representation using the __literal_eval()__ function. To convert the tokenized text to simple vector representation, the 'gensim' package was used to convert the tokenized text into a corpus and dictionary, as required by the LDA algorithm.\n",
    "\n",
    "The LDA prototype implementation has one major flaw, in that it does not keep the sequentiallity of the data. Refer to the output from LDA for the first 5 topics (Five topics as modelled by LDA). From this output it is evident that the words are not in a sequence that makes any sense. This is where a segmentation extension as suggested by Camelin et al. would be highly beneficial in the overall process of modeling topics. According to Thielman et al., the LDA classification method is able to classify text according to probabilistic topics with a greater than 80% average. This implementation of the LDA is unsupervised, with unlabelled data, and does therefore not have a test and training data set to calculate performance results.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Python Implementation\n",
    "\n",
    "#### Preprocessing of the Tokenized words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Preprocessing\n",
    "########################################################################\n",
    "# Use the ast package to convert the words for each Tweet \n",
    "# to a tokenized object\n",
    "data_words = []\n",
    "data_words = list(tweets_df.words.apply(\n",
    "    lambda x: ast.literal_eval(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the text into a Corpus and Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)]\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Create a Corpus and Dictionary\n",
    "########################################################################\n",
    "# Convert the tokenized object into a Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "# Convert the tokenized object into a Corpus\n",
    "texts = data_words\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Train the LDA model on the Tweets\n",
    "########################################################################\n",
    "# LDA model training\n",
    "\n",
    "# number of topics\n",
    "num_topics = 5\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Five topics as modelled by LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.036*\"variant\" + 0.016*\"case\" + 0.010*\"covid\" + 0.009*\"new\" + '\n",
      "  '0.006*\"vaccinated\" + 0.005*\"mild\" + 0.005*\"coronavirus\" + 0.005*\"vaccine\" + '\n",
      "  '0.005*\"massachusetts\" + 0.005*\"covid19\"'),\n",
      " (1,\n",
      "  '0.008*\"variant\" + 0.007*\"still\" + 0.007*\"covid19\" + 0.006*\"vaccine\" + '\n",
      "  '0.005*\"case\" + 0.005*\"new\" + 0.005*\"get\" + 0.005*\"time\" + 0.005*\"people\" + '\n",
      "  '0.005*\"like\"'),\n",
      " (2,\n",
      "  '0.011*\"variant\" + 0.009*\"people\" + 0.007*\"say\" + 0.006*\"uk\" + 0.006*\"like\" '\n",
      "  '+ 0.005*\"news\" + 0.005*\"one\" + 0.005*\"covid\" + 0.005*\"via\" + 0.005*\"virus\"'),\n",
      " (3,\n",
      "  '0.014*\"variant\" + 0.009*\"delta\" + 0.007*\"covid\" + 0.007*\"vaccine\" + '\n",
      "  '0.005*\"one\" + 0.005*\"amp\" + 0.005*\"new\" + 0.005*\"people\" + 0.004*\"u\" + '\n",
      "  '0.004*\"le\"'),\n",
      " (4,\n",
      "  '0.023*\"variant\" + 0.009*\"delta\" + 0.008*\"case\" + 0.006*\"vaccine\" + '\n",
      "  '0.006*\"first\" + 0.006*\"detected\" + 0.006*\"death\" + 0.005*\"day\" + '\n",
      "  '0.005*\"say\" + 0.004*\"new\"')]\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Print the keywords from the 5 topics\n",
    "########################################################################\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Task 2 - Sentiment analysis using VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Natural Language Processing, being able to understand the emotional tone underlying the text is a fundamental task, universally known as sentiment analysis, where the attempt is made to measure the positive or negative sentiment expressed in a message. According to Liu, textual information is classified into two main types, facts and opinions, and sentiment analysis can be used to determine the level of opinion expressions (Liu, 2010). Sentiment analysis is the process of describing whether a piece of text is positive, negative or neutral, and sentiment is defined as an attitude, thought or judgement promoted by feelings, which also forms part of the much larger study area known as Opinion Mining (Surve, 2019). According to Gaur and Sharma, sentiment analysis can be defined as a natural language process task to track the mood of the public about a particular product or topic (Gaur & Sharma, 2017). The VADER sentiment analysis engine, a simple rule-based model for general sentiment analysis, is presented as an effective engine for performing sentiment analysis on Social Media Text (Hutto & Gilbert, 2014). Gaining insight into the emotional undertone of text, and in this assignment, Tweets, create a mechanism for tracking the mood of public commentary.\n",
    "\n",
    "As mentioned in the Overview, Twitter is all about sentiment; people Tweet what they feel and think about... When presented with a Coronavirus variant such as Omicron, these Tweets also reflect their underlying fears and reservations. This NLP Task is used to prototype that sentiment, determining the emotional tone of the Tweets associated with Omicron. As the Twitter data is unlabelled with regards to its sentiment, the pre-built sentiment analysis engine VADER, with the __SentimentIntensityAnalyzer__ method is used for this prototype, using VADER's pre-defined lists of positive and negative words to measure the sentiment (downloaded from nltk).\n",
    "\n",
    "VADER operates on the original Tweeted text, therefore the only preprocessing required for it was removing the hyperlinks (URLS) and replacing the contractions (e.g. \"You're\" replaced with \"You are\"). The algorithm does not require any hyperparameters. Based on the results obtained by Hutto & Gilbert, it was found that VADER (with an F1 Classification Accuracy of 96%) outperforms human rators by more than 12%. Based on these results, a similar performance is expected for this sentiment analysis prototype.\n",
    "\n",
    "The results from the Sentiment Analysis is quite surprising, where the positive tweets are much higher than the negative tweets, which would indicate a more positive emotional tone to the Tweets related to Omicron. Could it be a case where people are no longer as frightened or intimidated by Coronavirus? \n",
    "\n",
    "Only the future will tell..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Python Implementation\n",
    "\n",
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Tweet Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet Length</th>\n",
       "      <th>words</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282552117501952</td>\n",
       "      <td>WHO says no deaths reported from Omicron yet a...</td>\n",
       "      <td>HappinessPatrol</td>\n",
       "      <td>145</td>\n",
       "      <td>['say', 'death', 'reported', 'yet', 'covid', '...</td>\n",
       "      <td>WHO says no deaths reported from Omicron yet a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282552075529984</td>\n",
       "      <td>Will the Omicron Travel Restrictions Work? - T...</td>\n",
       "      <td>ZZsheyn</td>\n",
       "      <td>83</td>\n",
       "      <td>['travel', 'restriction', 'work', 'new', 'york...</td>\n",
       "      <td>Will the Omicron Travel Restrictions Work? - T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282547906339072</td>\n",
       "      <td>@VaccineJo Omicron is simply a fitness test, a...</td>\n",
       "      <td>stevenjfrisch</td>\n",
       "      <td>148</td>\n",
       "      <td>['vaccinejo', 'simply', 'fitness', 'test', 'pr...</td>\n",
       "      <td>@VaccineJo Omicron is simply a fitness test, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282539433926912</td>\n",
       "      <td>@johnpavlovitz SWEET JESUS JOHN! WHY OH WHY! J...</td>\n",
       "      <td>butterflybees11</td>\n",
       "      <td>176</td>\n",
       "      <td>['johnpavlovitz', 'sweet', 'jesus', 'john', 'o...</td>\n",
       "      <td>@johnpavlovitz SWEET JESUS JOHN! WHY OH WHY! J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282530949033984</td>\n",
       "      <td>@Channel4News @krishgm I'm done humouring Fasc...</td>\n",
       "      <td>Anne_Other1</td>\n",
       "      <td>206</td>\n",
       "      <td>['channel4news', 'krishgm', 'done', 'humouring...</td>\n",
       "      <td>@Channel4News @krishgm I am done humouring Fas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467274440190816000</td>\n",
       "      <td>@_evelynrae The New Zealand Government is cert...</td>\n",
       "      <td>MBoxel</td>\n",
       "      <td>192</td>\n",
       "      <td>['_evelynrae', 'new', 'zealand', 'government',...</td>\n",
       "      <td>@_evelynrae The New Zealand Government is cert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467274436034416896</td>\n",
       "      <td>@HereComz_Woody @robeytech Yep, just got my bo...</td>\n",
       "      <td>63kk01</td>\n",
       "      <td>275</td>\n",
       "      <td>['herecomz_woody', 'robeytech', 'yep', 'got', ...</td>\n",
       "      <td>@HereComz_Woody @robeytech Yep, just got my bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467274435271041024</td>\n",
       "      <td>@ExeterChiefs @Saracens Chiefs beginning to ge...</td>\n",
       "      <td>theraithrover</td>\n",
       "      <td>235</td>\n",
       "      <td>['exeterchiefs', 'saracen', 'chief', 'beginnin...</td>\n",
       "      <td>@ExeterChiefs @Saracens Chiefs beginning to ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467274433085808896</td>\n",
       "      <td>What We Know About the New Covid Variant, Omic...</td>\n",
       "      <td>jlitwinetz</td>\n",
       "      <td>75</td>\n",
       "      <td>['know', 'new', 'covid', 'variant']</td>\n",
       "      <td>What We Know About the New Covid Variant, Omic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467274429658897920</td>\n",
       "      <td>Aus. Kids and Third doses / boosters. We need ...</td>\n",
       "      <td>PMGPSC</td>\n",
       "      <td>143</td>\n",
       "      <td>['au', 'kid', 'third', 'dos', 'booster', 'need...</td>\n",
       "      <td>Aus. Kids and Third doses / boosters. We need ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date             Tweet Id  \\\n",
       "0   2021-12-04  1467282552117501952   \n",
       "1   2021-12-04  1467282552075529984   \n",
       "2   2021-12-04  1467282547906339072   \n",
       "3   2021-12-04  1467282539433926912   \n",
       "4   2021-12-04  1467282530949033984   \n",
       "..         ...                  ...   \n",
       "995 2021-12-04  1467274440190816000   \n",
       "996 2021-12-04  1467274436034416896   \n",
       "997 2021-12-04  1467274435271041024   \n",
       "998 2021-12-04  1467274433085808896   \n",
       "999 2021-12-04  1467274429658897920   \n",
       "\n",
       "                                            Tweet Text         Username  \\\n",
       "0    WHO says no deaths reported from Omicron yet a...  HappinessPatrol   \n",
       "1    Will the Omicron Travel Restrictions Work? - T...          ZZsheyn   \n",
       "2    @VaccineJo Omicron is simply a fitness test, a...    stevenjfrisch   \n",
       "3    @johnpavlovitz SWEET JESUS JOHN! WHY OH WHY! J...  butterflybees11   \n",
       "4    @Channel4News @krishgm I'm done humouring Fasc...      Anne_Other1   \n",
       "..                                                 ...              ...   \n",
       "995  @_evelynrae The New Zealand Government is cert...           MBoxel   \n",
       "996  @HereComz_Woody @robeytech Yep, just got my bo...           63kk01   \n",
       "997  @ExeterChiefs @Saracens Chiefs beginning to ge...    theraithrover   \n",
       "998  What We Know About the New Covid Variant, Omic...       jlitwinetz   \n",
       "999  Aus. Kids and Third doses / boosters. We need ...           PMGPSC   \n",
       "\n",
       "     Tweet Length                                              words  \\\n",
       "0             145  ['say', 'death', 'reported', 'yet', 'covid', '...   \n",
       "1              83  ['travel', 'restriction', 'work', 'new', 'york...   \n",
       "2             148  ['vaccinejo', 'simply', 'fitness', 'test', 'pr...   \n",
       "3             176  ['johnpavlovitz', 'sweet', 'jesus', 'john', 'o...   \n",
       "4             206  ['channel4news', 'krishgm', 'done', 'humouring...   \n",
       "..            ...                                                ...   \n",
       "995           192  ['_evelynrae', 'new', 'zealand', 'government',...   \n",
       "996           275  ['herecomz_woody', 'robeytech', 'yep', 'got', ...   \n",
       "997           235  ['exeterchiefs', 'saracen', 'chief', 'beginnin...   \n",
       "998            75                ['know', 'new', 'covid', 'variant']   \n",
       "999           143  ['au', 'kid', 'third', 'dos', 'booster', 'need...   \n",
       "\n",
       "                                        cleaned_tweets  \n",
       "0    WHO says no deaths reported from Omicron yet a...  \n",
       "1    Will the Omicron Travel Restrictions Work? - T...  \n",
       "2    @VaccineJo Omicron is simply a fitness test, a...  \n",
       "3    @johnpavlovitz SWEET JESUS JOHN! WHY OH WHY! J...  \n",
       "4    @Channel4News @krishgm I am done humouring Fas...  \n",
       "..                                                 ...  \n",
       "995  @_evelynrae The New Zealand Government is cert...  \n",
       "996  @HereComz_Woody @robeytech Yep, just got my bo...  \n",
       "997  @ExeterChiefs @Saracens Chiefs beginning to ge...  \n",
       "998  What We Know About the New Covid Variant, Omic...  \n",
       "999  Aus. Kids and Third doses / boosters. We need ...  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################################################\n",
    "# Preprocessing\n",
    "########################################################################\n",
    "def replace_contractions(text):\n",
    "    \"\"\"Replace contractions in string of text\"\"\"\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def remove_URL(text):\n",
    "    \"\"\"Remove URLs from a text string\"\"\"\n",
    "    return re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "# Remove the URLS\n",
    "tweets_df[\"cleaned_tweets\"] = tweets_df['Tweet Text'].apply(\n",
    "                lambda x: remove_URL(x))\n",
    "\n",
    "# English contractions\n",
    "tweets_df[\"cleaned_tweets\"] = tweets_df['cleaned_tweets'].apply(\n",
    "                lambda x: replace_contractions(x))\n",
    "    \n",
    "display(tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/cmulder/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Tweet Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet Length</th>\n",
       "      <th>words</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>sentiment_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282552117501952</td>\n",
       "      <td>WHO says no deaths reported from Omicron yet a...</td>\n",
       "      <td>HappinessPatrol</td>\n",
       "      <td>145</td>\n",
       "      <td>['say', 'death', 'reported', 'yet', 'covid', '...</td>\n",
       "      <td>WHO says no deaths reported from Omicron yet a...</td>\n",
       "      <td>{'neg': 0.121, 'neu': 0.879, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282552075529984</td>\n",
       "      <td>Will the Omicron Travel Restrictions Work? - T...</td>\n",
       "      <td>ZZsheyn</td>\n",
       "      <td>83</td>\n",
       "      <td>['travel', 'restriction', 'work', 'new', 'york...</td>\n",
       "      <td>Will the Omicron Travel Restrictions Work? - T...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282547906339072</td>\n",
       "      <td>@VaccineJo Omicron is simply a fitness test, a...</td>\n",
       "      <td>stevenjfrisch</td>\n",
       "      <td>148</td>\n",
       "      <td>['vaccinejo', 'simply', 'fitness', 'test', 'pr...</td>\n",
       "      <td>@VaccineJo Omicron is simply a fitness test, a...</td>\n",
       "      <td>{'neg': 0.163, 'neu': 0.761, 'pos': 0.076, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282539433926912</td>\n",
       "      <td>@johnpavlovitz SWEET JESUS JOHN! WHY OH WHY! J...</td>\n",
       "      <td>butterflybees11</td>\n",
       "      <td>176</td>\n",
       "      <td>['johnpavlovitz', 'sweet', 'jesus', 'john', 'o...</td>\n",
       "      <td>@johnpavlovitz SWEET JESUS JOHN! WHY OH WHY! J...</td>\n",
       "      <td>{'neg': 0.113, 'neu': 0.701, 'pos': 0.186, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282530949033984</td>\n",
       "      <td>@Channel4News @krishgm I'm done humouring Fasc...</td>\n",
       "      <td>Anne_Other1</td>\n",
       "      <td>206</td>\n",
       "      <td>['channel4news', 'krishgm', 'done', 'humouring...</td>\n",
       "      <td>@Channel4News @krishgm I am done humouring Fas...</td>\n",
       "      <td>{'neg': 0.258, 'neu': 0.603, 'pos': 0.14, 'com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date             Tweet Id  \\\n",
       "0 2021-12-04  1467282552117501952   \n",
       "1 2021-12-04  1467282552075529984   \n",
       "2 2021-12-04  1467282547906339072   \n",
       "3 2021-12-04  1467282539433926912   \n",
       "4 2021-12-04  1467282530949033984   \n",
       "\n",
       "                                          Tweet Text         Username  \\\n",
       "0  WHO says no deaths reported from Omicron yet a...  HappinessPatrol   \n",
       "1  Will the Omicron Travel Restrictions Work? - T...          ZZsheyn   \n",
       "2  @VaccineJo Omicron is simply a fitness test, a...    stevenjfrisch   \n",
       "3  @johnpavlovitz SWEET JESUS JOHN! WHY OH WHY! J...  butterflybees11   \n",
       "4  @Channel4News @krishgm I'm done humouring Fasc...      Anne_Other1   \n",
       "\n",
       "   Tweet Length                                              words  \\\n",
       "0           145  ['say', 'death', 'reported', 'yet', 'covid', '...   \n",
       "1            83  ['travel', 'restriction', 'work', 'new', 'york...   \n",
       "2           148  ['vaccinejo', 'simply', 'fitness', 'test', 'pr...   \n",
       "3           176  ['johnpavlovitz', 'sweet', 'jesus', 'john', 'o...   \n",
       "4           206  ['channel4news', 'krishgm', 'done', 'humouring...   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0  WHO says no deaths reported from Omicron yet a...   \n",
       "1  Will the Omicron Travel Restrictions Work? - T...   \n",
       "2  @VaccineJo Omicron is simply a fitness test, a...   \n",
       "3  @johnpavlovitz SWEET JESUS JOHN! WHY OH WHY! J...   \n",
       "4  @Channel4News @krishgm I am done humouring Fas...   \n",
       "\n",
       "                                 sentiment_intensity  \n",
       "0  {'neg': 0.121, 'neu': 0.879, 'pos': 0.0, 'comp...  \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "2  {'neg': 0.163, 'neu': 0.761, 'pos': 0.076, 'co...  \n",
       "3  {'neg': 0.113, 'neu': 0.701, 'pos': 0.186, 'co...  \n",
       "4  {'neg': 0.258, 'neu': 0.603, 'pos': 0.14, 'com...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################################\n",
    "# Perform Sentiment Analysis using VADER\n",
    "########################################################################\n",
    "# Download the VADER lexicon, containing the positive and negative words\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Set up the Sentiment Intensity Analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "tweets_df['sentiment_intensity'] = tweets_df.apply(\n",
    "    lambda row: sid.polarity_scores(row.cleaned_tweets), axis=1)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Tweet Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet Length</th>\n",
       "      <th>words</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>sentiment_intensity</th>\n",
       "      <th>compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282552117501952</td>\n",
       "      <td>WHO says no deaths reported from Omicron yet a...</td>\n",
       "      <td>HappinessPatrol</td>\n",
       "      <td>145</td>\n",
       "      <td>['say', 'death', 'reported', 'yet', 'covid', '...</td>\n",
       "      <td>WHO says no deaths reported from Omicron yet a...</td>\n",
       "      <td>{'neg': 0.121, 'neu': 0.879, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282552075529984</td>\n",
       "      <td>Will the Omicron Travel Restrictions Work? - T...</td>\n",
       "      <td>ZZsheyn</td>\n",
       "      <td>83</td>\n",
       "      <td>['travel', 'restriction', 'work', 'new', 'york...</td>\n",
       "      <td>Will the Omicron Travel Restrictions Work? - T...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282547906339072</td>\n",
       "      <td>@VaccineJo Omicron is simply a fitness test, a...</td>\n",
       "      <td>stevenjfrisch</td>\n",
       "      <td>148</td>\n",
       "      <td>['vaccinejo', 'simply', 'fitness', 'test', 'pr...</td>\n",
       "      <td>@VaccineJo Omicron is simply a fitness test, a...</td>\n",
       "      <td>{'neg': 0.163, 'neu': 0.761, 'pos': 0.076, 'co...</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282539433926912</td>\n",
       "      <td>@johnpavlovitz SWEET JESUS JOHN! WHY OH WHY! J...</td>\n",
       "      <td>butterflybees11</td>\n",
       "      <td>176</td>\n",
       "      <td>['johnpavlovitz', 'sweet', 'jesus', 'john', 'o...</td>\n",
       "      <td>@johnpavlovitz SWEET JESUS JOHN! WHY OH WHY! J...</td>\n",
       "      <td>{'neg': 0.113, 'neu': 0.701, 'pos': 0.186, 'co...</td>\n",
       "      <td>0.5984</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>1467282530949033984</td>\n",
       "      <td>@Channel4News @krishgm I'm done humouring Fasc...</td>\n",
       "      <td>Anne_Other1</td>\n",
       "      <td>206</td>\n",
       "      <td>['channel4news', 'krishgm', 'done', 'humouring...</td>\n",
       "      <td>@Channel4News @krishgm I am done humouring Fas...</td>\n",
       "      <td>{'neg': 0.258, 'neu': 0.603, 'pos': 0.14, 'com...</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date             Tweet Id  \\\n",
       "0 2021-12-04  1467282552117501952   \n",
       "1 2021-12-04  1467282552075529984   \n",
       "2 2021-12-04  1467282547906339072   \n",
       "3 2021-12-04  1467282539433926912   \n",
       "4 2021-12-04  1467282530949033984   \n",
       "\n",
       "                                          Tweet Text         Username  \\\n",
       "0  WHO says no deaths reported from Omicron yet a...  HappinessPatrol   \n",
       "1  Will the Omicron Travel Restrictions Work? - T...          ZZsheyn   \n",
       "2  @VaccineJo Omicron is simply a fitness test, a...    stevenjfrisch   \n",
       "3  @johnpavlovitz SWEET JESUS JOHN! WHY OH WHY! J...  butterflybees11   \n",
       "4  @Channel4News @krishgm I'm done humouring Fasc...      Anne_Other1   \n",
       "\n",
       "   Tweet Length                                              words  \\\n",
       "0           145  ['say', 'death', 'reported', 'yet', 'covid', '...   \n",
       "1            83  ['travel', 'restriction', 'work', 'new', 'york...   \n",
       "2           148  ['vaccinejo', 'simply', 'fitness', 'test', 'pr...   \n",
       "3           176  ['johnpavlovitz', 'sweet', 'jesus', 'john', 'o...   \n",
       "4           206  ['channel4news', 'krishgm', 'done', 'humouring...   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0  WHO says no deaths reported from Omicron yet a...   \n",
       "1  Will the Omicron Travel Restrictions Work? - T...   \n",
       "2  @VaccineJo Omicron is simply a fitness test, a...   \n",
       "3  @johnpavlovitz SWEET JESUS JOHN! WHY OH WHY! J...   \n",
       "4  @Channel4News @krishgm I am done humouring Fas...   \n",
       "\n",
       "                                 sentiment_intensity  compound Sentiment  \n",
       "0  {'neg': 0.121, 'neu': 0.879, 'pos': 0.0, 'comp...   -0.2960       neg  \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000       pos  \n",
       "2  {'neg': 0.163, 'neu': 0.761, 'pos': 0.076, 'co...   -0.3400       neg  \n",
       "3  {'neg': 0.113, 'neu': 0.701, 'pos': 0.186, 'co...    0.5984       pos  \n",
       "4  {'neg': 0.258, 'neu': 0.603, 'pos': 0.14, 'com...   -0.6486       neg  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################################\n",
    "# Extract the sentiment as pos or neg\n",
    "########################################################################\n",
    "# We are only interested in the compound section of the Sentiment Intensity\n",
    "# Extract the Compound from the Sentiments \n",
    "tweets_df['compound']  = tweets_df['sentiment_intensity'].apply(\n",
    "    lambda score_dict: score_dict['compound'])\n",
    "\n",
    "# Convert the compound to a positive/negative label\n",
    "tweets_df['Sentiment'] = tweets_df['compound'].apply(\n",
    "    lambda c: 'pos' if c >=0 else 'neg')\n",
    "\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the sentiment_intensity and compound columns from the dataframe\n",
    "del tweets_df['sentiment_intensity']\n",
    "del tweets_df['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################################################\n",
    "# Plot the results\n",
    "########################################################################\n",
    "import seaborn\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seaborn.set() #make the plots look pretty\n",
    "# Create a dataframe containing only the Tweet Id and Sentiment\n",
    "sentiment_df = tweets_df[['Tweet Id', 'Sentiment']]\n",
    "\n",
    "ag = sentiment_df.groupby(['Sentiment']).sum().unstack()\n",
    "\n",
    "ag.plot(kind = 'bar', colormap = cm.Accent, width = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Camelin, N., Detienne, B., Huet, S., Quadri, D., & Lefevre, F. (2011). Unsupervised Concept Annotation using Latent Dirichlet Allocation and Segmental Methods. Proceedings of EMNLP 2011( Conference on Empirical Methods in Natural Language Processing), 78-81. \n",
    "\n",
    "Gaur, N., & Sharma, N. (2017). Sentiment Analysis in Natural Language Processing. International Journal of Engineering and Techniques, 3(3). www.ijetjournal.org \n",
    "\n",
    "Hutto, C. J., & Gilbert, E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Association for the Advancement of Artificial Intelligence. http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf \n",
    "\n",
    "I.V, S. (2016). Sentiment Analysis in Python using NLTK. OSFY - OpensourceForYou. \n",
    "\n",
    "Liu, B. (2010). Handbook of Natural Language Processing (N. I. a. F. J. Damerau, Ed. Second Edition ed.)  \n",
    "\n",
    "Surve, N. H. (2019). Sentiment Analysis using Natural Language Processing (NLP). International Research Journal of Engineering and Technology (IRJET), 06(09). www.irjet.net \n",
    "\n",
    "Thielmann, A., Weisser, C., Krenz, A., & SÃ¤fken, B. (2020). Unsupervised Document Classification integrating Web Scraping, One-Class SVM and LDA Topic Modelling. \n",
    "\n",
    "Wang, F., Wang, Q., Nie, F., Li, Z., Yu, W., & Wang, R. (2021). Unsupervised Linear Discriminant Analysis for Jointly Clustering and Subspace Learning. IEEE Transactions on Knowledge and Data Engineering, 33, 1276-1290. https://doi.org/10.1109/TKDE.2019.2939524 \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b8be56cfe10e907251ce2d76bda2f6a442ace68dc2a60382ab7fca985e07926"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
