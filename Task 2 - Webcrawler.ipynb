{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "## Web-crawler 1.0\n",
    "## Created by:  Coenraad F. Mulder\n",
    "## Date:        01-12-2021\n",
    "## Purpose:     Webscrape Twitter feed for specific hashtags, \n",
    "##              then supplement\n",
    "##              with additional information from the Twitter API\n",
    "#######################################################################\n",
    "# Libraries\n",
    "#######################################################################\n",
    "import requests                                             # For getting URLS from the Web\n",
    "import pandas as pd                                         # DataFrame functionality\n",
    "import snscrape.modules.twitter as sntwitter                # Python Scraper Library for Twitter feed\n",
    "from datetime import datetime, timedelta                    # Date and time manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webcrawler | Task 2\n",
    "This assignment uses the 'snscrape' library (created by JustAnotherArchivist), a social networking services scraper. The primary focus of this assignment is the Twitter platform (https://www.twitter.com), specifically focusing on the hype that is created on this platform when a new variant of Coronavirus is identified. The latest variant, Omicron, has been identified less than two weeks ago, which has caused a surge in social media commentary from both experts and amateurs alike. This begs the question, what are the issues that people are discussing around Omicron, and is the prevalent sentiment around it positive or negative? Is this variant as infectuous and deadly as its predecessor, or is its' impact just amplified through unsolicited social commentary fueled by fear and uncertainty? To investigate these issues, this web crawler was created to scrape a specified number of tweets, spanning a specified number of days, and covering all English language tweets during this period, around a specified keyword. For instance, this assignment uses the Twitter Web Crawler to scrape Twitter for all tweets between the 5th of December 2021 and the 14 days leading up to it, limiting the tweets to 1000 tweets, and using the keyword search term 'Omicron' (refer to the Hyper-parameters for the Scraper code segment below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Hyper-parameters for the Scraper\n",
    "#######################################################################\n",
    "date_to = '2021-12-05'\n",
    "number_of_days = 14\n",
    "tweet_limit = 1000\n",
    "search_term = 'omicron'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Twitter Web Crawler class\n",
    "#######################################################################\n",
    "### INPUT\n",
    "#----------------------------------------------------------------------\n",
    "#   search_term    : Term to search Twitter with\n",
    "#   search_limit   : Maximum number of tweets to return  \n",
    "#   search_to_date : End date for date range in format yyyy-mm-dd \n",
    "#   number_of_days : Number of days to go back in history  \n",
    "#\n",
    "### OUTPUT\n",
    "#----------------------------------------------------------------------\n",
    "#   tweets.xlsx    : Excel spreadsheet containing:\n",
    "#                       - Date\n",
    "#                       - Tweet Id\n",
    "#                       - Tweet Text\n",
    "#                       - Username of Tweeter\n",
    "#                       - Tweet Length\n",
    "#######################################################################\n",
    "class TwitterWebCrawler():\n",
    "    ###################################################################\n",
    "    # CONSTRUCTOR                                                     \n",
    "    ###################################################################\n",
    "    def __init__(self, search_term, search_limit, search_to_date, number_of_days):\n",
    "        dt_to = self.validate_date(input_date = search_to_date)\n",
    "        \n",
    "        if(dt_to == None):\n",
    "            raise Exception(\"Invalid search_to_date supplied! Value must be in format yyyy-mm-dd.\")\n",
    "\n",
    "        dt_from = self.calc_from_date(dt_to, number_of_days)\n",
    "        date_from = dt_from.strftime(\"%Y-%m-%d\")\n",
    "        date_to = dt_to.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Set the search terms for twitter specifying from and to dates\n",
    "        # Only return English Tweets\n",
    "        self.search_term = search_term + ' since:' + date_from + ' until:' + date_to + ' lang:en' \n",
    "        self.search_limit = search_limit\n",
    "        self.tweets_df = pd.DataFrame(columns=['Date', 'Tweet Id', 'Tweet Text', 'Username', 'Tweet Length'])\n",
    "            \n",
    "    ###################################################################\n",
    "    # Validate Date \n",
    "    ###################################################################\n",
    "    # Purpose:  Check for a valid formatted date\n",
    "    #           Date must be in format 'yyyy-mm-dd'\n",
    "    # Input:    input_date      string      yyyy-mm-dd\n",
    "    # Output:   result         boolean     True/False\n",
    "    ###################################################################\n",
    "    def validate_date(self, input_date):\n",
    "        try:\n",
    "            # Attempt to construct a date from the input_date\n",
    "            return datetime.strptime(input_date, \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    ###################################################################\n",
    "    # Calculate Start Date  \n",
    "    ###################################################################\n",
    "    # Purpose:  Calculate start date from input_datetime (offset by number_of_days)\n",
    "    #           Date must be valid datetime format\n",
    "    # Input:    input_datetime      datetime      yyyy-mm-dd\n",
    "    #           number_of_days      integer       >0\n",
    "    # Output:   result              datetime      True/False\n",
    "    ###################################################################\n",
    "    def calc_from_date(self, input_datetime, number_of_days):\n",
    "        try:\n",
    "            return input_datetime - timedelta(days=number_of_days)\n",
    "        except ValueError:\n",
    "            return None\n",
    "        except TypeError:\n",
    "            return None\n",
    "    \n",
    "    ###################################################################\n",
    "    # Main execution thread for Twitter Web Crawler\n",
    "    ###################################################################\n",
    "    def run(self):\n",
    "        try:\n",
    "            print(datetime.now(), \"Extracting tweets using search term: \", self.search_term)\n",
    "\n",
    "            # Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "            twitter_items = sntwitter.TwitterSearchScraper(self.search_term).get_items()\n",
    "\n",
    "            print(datetime.now(), \"Processing tweets...\")\n",
    "            for idx,tweet in enumerate(twitter_items):\n",
    "                # Only retrieve records up to search_limit of tweets\n",
    "                if idx >= self.search_limit:\n",
    "                    break\n",
    "\n",
    "                tweet_length = len(str(tweet.content))\n",
    "\n",
    "                # Add the extracted tweet to the Tweets dataframe \n",
    "                self.tweets_df.loc[len(self.tweets_df)] = [tweet.date, tweet.id, tweet.content, tweet.username, tweet_length]\n",
    "            \n",
    "            self.save_data_to_file()\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise Exception(e)\n",
    "\n",
    "    ###################################################################\n",
    "    # Save dataframe to Excel  \n",
    "    ###################################################################\n",
    "    # Purpose:  Save dateframe to Excel for further processing\n",
    "    # Input:    -\n",
    "    # Output:   tweets.xlsx saved in same directory as files\n",
    "    ###################################################################\n",
    "    def save_data_to_file(self):\n",
    "        try:\n",
    "            # Dates are implicitly stored as DateTime with Timezone in pandas dataframe - Remove timezone before storing to Excel\n",
    "            self.tweets_df['Date'] = self.tweets_df['Date'].apply(lambda a: pd.to_datetime(a).date())\n",
    "\n",
    "            # Save the dataframe content to an Excel file (as it is possible for the tweets to contain commas, which will break CSV format\n",
    "            self.tweets_df.to_excel('tweets.xlsx', index = None, header=True)\n",
    "            print(datetime.now(), \"Tweet results successfully saved to the file 'tweets.xlsx'\")\n",
    "        except Exception as e:\n",
    "            raise Exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-05 12:46:08.175087 Extracting tweets using search term:  omicron since:2021-11-21 until:2021-12-05 lang:en\n",
      "2021-12-05 12:46:08.175409 Processing tweets...\n",
      "2021-12-05 12:46:41.960004 Tweet results successfully saved to the file 'tweets.xlsx'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        mycrawler = TwitterWebCrawler(\n",
    "            search_term = search_term, \n",
    "            search_limit = tweet_limit, \n",
    "            search_to_date = date_to, \n",
    "            number_of_days = number_of_days)\n",
    "        mycrawler.run()\n",
    "    except Exception as e:\n",
    "        print(datetime.now(), \"ERROR OCCURRED!\", str(e))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b8be56cfe10e907251ce2d76bda2f6a442ace68dc2a60382ab7fca985e07926"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
